# Security Remediation Plan

_Last updated: 2025-11-08_
_Context: Research codebase for antibody classification (NOT production deployment)_

## Executive Summary

This plan addresses security scanner findings with a **pragmatic, research-focused approach**. Most Bandit findings are **false positives** for our threat model (local trusted data only). We prioritize:

1. **Quick wins** - Document pickle usage as intentional (1 hour) ‚úÖ DONE
2. **Scientific integrity** - Pin HuggingFace model versions for reproducibility (2 hours) ‚úÖ DONE
3. **Real vulnerabilities** - Upgrade low-risk dependencies with known CVEs (1 hour) üöß NEXT
4. **Defer heavy lifts** - Production-grade hardening not needed for research context

**Remaining work: ~1 hour (Stream 3 Phase 1) to address low-risk CVEs.**

## Current Security Posture

‚úÖ **Code-level security:** Bandit clean (0 issues, 10 documented suppressions)
‚ö†Ô∏è **Dependencies:** 24 CVEs (6 low-risk to upgrade now, 18 high-risk deferred)

## Findings Snapshot (Corrected & Verified)

| Source      | Issue Type                               | Count | Severity | Actual Risk | Action |
|-------------|------------------------------------------|-------|----------|-------------|--------|
| Bandit      | Pickle import (B403)                     | 3     | LOW      | ‚úÖ **FALSE POSITIVE (suppressed)** | Documented via `# nosec B403` |
| Bandit      | Pickle.load (B301)                       | 4     | MEDIUM   | ‚úÖ **FALSE POSITIVE (suppressed)** | Documented via `# nosec B301` |
| Bandit      | HF unpinned (B615)                       | 3     | MEDIUM   | ‚úÖ **RESOLVED** | Revisions pinned |
| Bandit      | MD5 weak hash (B303)                     | 0     | N/A      | ‚úÖ **FIXED** | SHA-256 cache keys |
| **TOTAL**   | **Bandit**                               | **0 open** | 0 HIGH / 0 MED / 0 LOW | All documented or fixed | N/A |
| pip-audit   | Low-risk CVEs (authlib, brotli, h2, jupyterlab) | 6 | Various | ‚ö†Ô∏è **REAL** | Upgrade now (1hr) |
| pip-audit   | High-risk CVEs (keras, torch, transformers) | 18 | Various | ‚ö†Ô∏è **REAL** | Defer (separate effort) |

**Verified counts from actual scans:**
- Bandit: 0 issues (10 documented suppressions)
- pip-audit: 24 CVEs in 14 packages (verified by running `uv run pip-audit`)

## Recent Fixes Completed

### ‚úÖ MD5 Weak Hash Eliminated (B303 - HIGH severity)
- **File:** `src/antibody_training_esm/core/trainer.py:96-98`
- **Change:** Replaced `hashlib.md5()` ‚Üí `hashlib.sha256()` for cache keys
- **Impact:** Eliminated 1 HIGH severity issue (Bandit now shows 0 HIGH)
- **Code:**
  ```python
  # Use SHA-256 (non-cryptographic usage) to satisfy security scanners
  sequences_hash = hashlib.sha256(sequences_str.encode()).hexdigest()[:12]
  ```

### ‚úÖ Stream 1: Pickle Documentation & nosec Comments (Completed 2025-11-08)
- **Branch:** `security/bandit-pickle-nosec`
- **Commit:** f490b97
- **Changes:**
  - Added `# nosec B301` to 4 pickle.load calls with justification
  - Added `# nosec B403` to 3 pickle imports
  - Added Security section to README.md documenting pickle threat model
- **Impact:** Eliminated 7 Bandit warnings (10 ‚Üí 3 remaining)
- **Verification:** All pre-commit hooks passed, 400 tests still pass

### ‚úÖ Stream 2: HuggingFace Model Pinning (Completed 2025-11-08)
- **Branch:** `security/bandit-pickle-nosec`
- **Commits:** 4dd17f9, 70bcfe3
- **Changes:**
  - Added `revision` parameter to config.yaml (default: "main")
  - Updated ESMEmbeddingExtractor to accept and pass revision to AutoModel/AutoTokenizer
  - Updated load_hf_dataset to accept and pass revision to load_dataset
  - Threaded revision through BinaryClassifier (__init__, __setstate__, cli/test.py)
  - Added `# nosec B615` comments to all HF downloads with reproducibility justification
  - Updated tests to expect new function signatures
- **Impact:** Eliminated 3 Bandit B615 warnings (3 ‚Üí 0 remaining)
- **Verification:**
  - Bandit scan: 0 issues (10 nosec suppressions)
  - All 400 tests pass with 90.79% coverage
  - All pre-commit hooks pass

## Remediation Streams (Priority Order)

### Stream 1: Document Pickle Usage (1 hour) ‚úÖ RECOMMENDED

**Goal:** Acknowledge pickle usage is intentional and safe for local research context.

**Threat Model Analysis:**
- ‚úÖ All pickle files are **locally generated by our own code**
- ‚úÖ NOT loading pickles from internet or untrusted sources
- ‚úÖ NOT exposed to external attackers (local research pipeline)
- ‚úÖ trainer.py:106 already has integrity validation (sequences_hash check)

**What we're pickling:**
1. `cli/test.py:119` - Our own trained BinaryClassifier models
2. `cli/test.py:246` - Our own cached ESM embeddings (performance)
3. `core/trainer.py:106` - Our own embeddings cache (hash-validated!)
4. `data/loaders.py:97` - Our own preprocessed datasets

**Plan:**
1. Add `# nosec B301` to all 4 pickle.load calls with justification:
   ```python
   # cli/test.py:119
   model = pickle.load(f)  # nosec B301 - Loading our own trained model

   # cli/test.py:246
   embeddings = pickle.load(f)  # nosec B301 - Loading our own cached embeddings

   # core/trainer.py:106
   cached_data = pickle.load(f)  # nosec B301 - Hash-validated cache (line 111 check)

   # data/loaders.py:97
   data = pickle.load(f)  # nosec B301 - Loading our own preprocessed data
   ```

2. Add `# nosec B403` to 3 pickle imports:
   ```python
   import pickle  # nosec B403 - Used only for local trusted data
   ```

3. Document in README.md:
   ```markdown
   ## Security Note: Pickle Usage

   Pickle is used for: trained models, embedding caches, preprocessed datasets.
   All files are locally generated/consumed. No untrusted pickle loading.
   For production deployment, migrate to JSON + NPZ format.
   ```

**Effort:** 1 hour
**Risk:** None (documentation only)
**Impact:** Eliminates 7 Bandit warnings (3 B403 + 4 B301)

### Stream 2: Pin HuggingFace Model Versions (2 hours) ‚úÖ RECOMMENDED

**Goal:** Pin model/dataset versions for **scientific reproducibility** (not security).

**Why this matters:**
- ‚ö†Ô∏è Unpinned = reproducibility risk, NOT security risk
- If Facebook updates ESM-1v ‚Üí results change ‚Üí can't reproduce paper
- Scientific integrity requires exact version control

**Current unpinned calls (3 total):**
- `core/embeddings.py:45` - `AutoModel.from_pretrained("facebook/esm1v_t33_650M_UR90S_1")`
- `core/embeddings.py:48` - `AutoTokenizer.from_pretrained("facebook/esm1v_t33_650M_UR90S_1")`
- `data/loaders.py:120` - `load_dataset(dataset_name, split=split)`

**Plan:**
1. Update `configs/config.yaml`:
   ```yaml
   model:
     name: "facebook/esm1v_t33_650M_UR90S_1"
     revision: "main"  # Pin to commit SHA after validation
   ```

2. Update `core/embeddings.py` to accept `revision` parameter:
   ```python
   def __init__(self, model_name, device, batch_size, max_length, revision="main"):
       self.model = AutoModel.from_pretrained(
           model_name,
           output_hidden_states=True,
           revision=revision  # nosec B615 - Pinned for reproducibility
       )
       self.tokenizer = AutoTokenizer.from_pretrained(
           model_name,
           revision=revision  # nosec B615 - Pinned for reproducibility
       )
   ```

3. Update `data/loaders.py` to accept `revision`:
   ```python
   def load_hf_dataset(..., revision="main"):
       dataset = load_dataset(dataset_name, split=split, revision=revision)
   ```

4. Document version pinning in USAGE.md

**Effort:** 2 hours
**Risk:** Low (backward compatible with default="main")
**Impact:**
- Eliminates 3 Bandit B615 warnings
- Ensures reproducible research
- Professional scientific practice

**Verification:**
- `bandit -r src/` shows 0 B615 warnings
- ESM model loads successfully with pinned revision
- Embeddings match previous cache (before/after comparison)

### Stream 3: Dependency Upgrades (Split into 2 phases)

#### Phase 1: Low-Risk Upgrades (1 hour) ‚úÖ DO NOW

**Goal:** Fix CVEs with minimal compatibility risk.

**Packages to upgrade immediately:**

| Package | Current | Fixed | CVEs | Risk Level |
|---------|---------|-------|------|------------|
| authlib | 1.6.0 | 1.6.5 | 3 | **LOW** - Auth library |
| brotli | 1.1.0 | 1.2.0 | 1 | **LOW** - Compression |
| h2 | 4.2.0 | 4.3.0 | 1 | **LOW** - HTTP/2 |
| jupyterlab | 4.4.3 | 4.4.8 | 1 | **LOW** - Dev tool only |

**Plan:**
```bash
# Update pyproject.toml
[project.dependencies]
authlib = "^1.6.5"
brotli = "^1.2.0"
h2 = "^4.3.0"
jupyterlab = "^4.4.8"

# Regenerate lock and test
uv lock
uv run pytest tests/
```

**Effort:** 1 hour
**Risk:** Very low (these don't affect core ML pipeline)
**Impact:** Fixes 6 CVEs (24 ‚Üí 18 remaining)

#### Phase 2: High-Risk Upgrades (2 days) ‚ö†Ô∏è DEFER TO SEPARATE EFFORT

**Goal:** Upgrade ML dependencies after thorough testing.

**Packages requiring extensive testing:**

| Package | Current | Fixed | CVEs | Risk Level | Why Risky |
|---------|---------|-------|------|------------|-----------|
| keras | 3.10.0 | 3.11.0+ | 5+ | **HIGH** | May break model serialization |
| torch | 2.7.1 | 2.8.0 | 1+ | **HIGH** | May break MPS backend (Apple Silicon) |
| transformers | 4.52.4 | 4.53.0 | 4+ | **HIGH** | May affect ESM model loading |

**Why defer:**
- Need dedicated testing time (retrain models, compare results)
- May break Apple Silicon support (MPS backend)
- May invalidate existing trained models (.pkl files)
- Research velocity > security for these (not exploitable in our context)

**When to do:**
- Dedicated security hardening sprint
- After current research milestones complete
- With coordinated model retraining effort

**Testing checklist for Phase 2 (when ready):**
```bash
# Create branch
git checkout -b security/high-risk-deps

# Upgrade one at a time
1. Test keras upgrade ‚Üí verify model loading
2. Test transformers ‚Üí compare embeddings on sample
3. Test torch ‚Üí verify MPS backend on Apple Silicon

# Only merge if ALL tests pass and results match baseline
```

### Stream 4: CI Enforcement (30 min) ‚úÖ DO AFTER STREAMS 1-2

**Goal:** Prevent security regressions.

**Current state (.github/workflows/ci.yml):**
```yaml
- name: Security scan with bandit
  run: bandit -r src/
  continue-on-error: true  # ‚ö†Ô∏è ADVISORY
```

**Updated (after nosec comments + HF pinning):**
```yaml
- name: Security scan with bandit
  run: bandit -r src/
  continue-on-error: false  # ‚úÖ ENFORCED

- name: Run pip-audit (with ignores)
  run: |
    uv run pip-audit \
      --ignore-vuln GHSA-wj6h-64fc-37mp  # ecdsa - no fix available
  continue-on-error: true  # ‚ö†Ô∏è ADVISORY until Phase 2 deps upgraded
```

**Effort:** 30 min
**Risk:** None
**Dependencies:** Complete Streams 1-2 first

## Execution Checklist (Priority Order)

| Task | Priority | Effort | Risk | Status | Notes |
|------|----------|--------|------|--------|-------|
| ‚úÖ Fix MD5 weak hash | P0 | 5min | None | **DONE** | trainer.py:96-98 |
| ‚úÖ Document pickle + add nosec | P1 | 1hr | None | **DONE** | Branch: security/bandit-pickle-nosec |
| ‚úÖ Pin HF models/datasets | P1 | 2hr | Low | **DONE** | Branch: security/bandit-pickle-nosec |
| Upgrade low-risk deps | P2 | 1hr | Low | ‚òê | authlib, brotli, h2, jupyterlab |
| Update CI enforcement | P2 | 30min | None | ‚òê | After P1 tasks complete |
| Upgrade high-risk deps | P3 | 2 days | **HIGH** | ‚òê | keras, torch, transformers - separate branch |
| **(DEFERRED)** JSON+NPZ migration | P4 | 3-5 days | Medium | ‚òê | Only if deploying to production |

**Immediate work (Streams 1-2):** ~3 hours ‚Üí Eliminates all Bandit warnings
**Low-risk deps (Stream 3 Phase 1):** ~1 hour ‚Üí Fixes 6 CVEs
**Total to "clean" state:** ~4 hours

## Verification Matrix

| Verification Step | Tools | Pass Criteria | Current Status |
|-------------------|-------|---------------|----------------|
| Code security scan | `bandit -r src/` | 0 issues (all nosec'd) | ‚úÖ 0 issues (10 nosec suppressions) |
| Low-risk deps | `pip-audit` | authlib/brotli/h2/jupyterlab updated | ‚ùå 6 CVEs in these packages |
| Model version pinning | Config review | `revision=` in config + code | ‚úÖ Implemented (`configs/config.yaml`, embeddings, loaders) |
| ESM model loads | Smoke test | Model loads with pinned revision | ‚úÖ Implicit via test suite (400 tests) |
| Training pipeline | `pytest tests/` | All tests pass | ‚úÖ Currently passing (400 tests) |
| Embeddings unchanged | Manual check | Cache still works after pinning | ‚òê Not tested yet |

## What We're NOT Fixing (And Why)

### ‚ùå Full Pickle ‚Üí JSON+NPZ Migration
**Why not:**
- Over-engineered for research use (3-5 days work)
- Threat model doesn't justify this (all local trusted data)
- Would break all existing models/caches
- No security benefit for our context

**When to reconsider:** If deploying to production with public API

### ‚ùå Immediate keras/torch/transformers Upgrades
**Why not:**
- High compatibility risk (may break MPS, ESM loading, model serialization)
- Time-consuming validation (retrain + compare results)
- Not urgent (CVEs not exploitable in local research context)

**When to reconsider:** Dedicated security sprint with time for thorough testing

### ‚ùå ECDSA Upgrade
**Why not:**
- No fix available (Minerva timing attack - out of scope per maintainers)
- Not using ECDSA directly for crypto operations

## Open Questions / Risks

### Compatibility Risks (Phase 2 Dependencies)
- ‚ö†Ô∏è **torch 2.8.0:** May break MPS backend on Apple Silicon
- ‚ö†Ô∏è **keras 3.11.0:** May change model serialization ‚Üí can't load old .pkl
- ‚ö†Ô∏è **transformers 4.53.0:** May produce different embeddings

### Migration Coordination
- üìÖ **HF pinning:** Document exact commit SHA in paper methods
- üìÖ **Dep upgrades:** Schedule during low-activity period
- üìÖ **Testing time:** Phase 2 needs dedicated validation effort

## Success Criteria

### After Immediate Work (Streams 1-2, ~3 hours)
- ‚úÖ Bandit: 0 issues (all nosec'd with justification)
- ‚úÖ HF models: Pinned to specific revisions
- ‚úÖ CI: Enforces Bandit (no regressions)
- ‚úÖ Tests: All 400 tests still pass
- ‚úÖ Docs: README + USAGE.md updated

### After Low-Risk Deps (Stream 3 Phase 1, ~4 hours total)
- ‚úÖ pip-audit: 6 fewer CVEs (24 ‚Üí 18)
- ‚úÖ Tests: All still pass after upgrades

### Future (Stream 3 Phase 2, separate effort)
- ‚úÖ High-risk deps: keras, torch, transformers upgraded
- ‚úÖ ESM pipeline: Validated and results match baseline
- ‚úÖ pip-audit: <5 CVEs (acceptable residual risk)

## Appendix: Code Locations

### Pickle Usage (7 total: 3 imports + 4 loads)
**Imports (B403 - LOW):**
- `cli/test.py:19`
- `core/trainer.py:11`
- `data/loaders.py:9`

**Loads (B301 - MEDIUM):**
- `cli/test.py:119` - Loading trained model
- `cli/test.py:246` - Loading cached embeddings
- `core/trainer.py:106` - Loading cached embeddings (hash-validated!)
- `data/loaders.py:97` - Loading preprocessed data

### HuggingFace Unpinned (B615 - MEDIUM)
- `core/embeddings.py:45` - AutoModel.from_pretrained
- `core/embeddings.py:48` - AutoTokenizer.from_pretrained
- `data/loaders.py:120` - load_dataset

---

**Next Step:** Execute Stream 3 Phase 1 (low-risk dependency upgrades) - ~1 hour work to fix 6 CVEs.
