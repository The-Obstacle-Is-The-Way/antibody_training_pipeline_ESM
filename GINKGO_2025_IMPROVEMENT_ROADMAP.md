# Ginkgo 2025 Competition: Improvement Roadmap

**Status:** 3rd place (0.500 Spearman) | Leader: 0.504 | Gap: -0.8%

**Last Updated:** 2025-11-13

---

## ðŸŽ¯ Current Best Model

**Model:** ESM-1v (62.8%) + p-IgGen (36.2%) ensemble with Ridge regression (Î±=5.5)

**Performance:**
- Mean per-fold Spearman: **0.50043**
- Per-fold breakdown: [0.478, 0.556, 0.672, 0.216, 0.580]
- **Problem:** Fold 3 (0.216) is killing overall score

**Files:**
- Script: `scripts/generate_optimal_submission.py`
- Submissions: `ginkgo_submissions_optimal/`
- Results: `experiment_results/top3_experiments_results.csv`

---

## ðŸ“Š What We Tried (And What Worked/Failed)

### âœ… Successes

1. **VH+VL Concatenation** (0.465 â†’ 0.476)
   - Key insight: Full antibody context beats individual chains

2. **Two-Model Ensemble** (0.476 â†’ 0.486)
   - ESM-1v (70%) + ESM-2 (30%)
   - Different embeddings = uncorrelated errors

3. **p-IgGen Addition** (0.486 â†’ 0.500)
   - Antibody-specific PLM beats general protein PLM
   - Optimal weights: 62.8% ESM-1v + 36.2% p-IgGen

4. **Alpha Micro-tuning** (Î±=7.0 â†’ Î±=5.5)
   - Fine-grained regularization tuning: +0.004 gain

### âŒ Failures

1. **Boughter Transfer Learning** (0.500 â†’ 0.491, **-1.93%**)
   - **Why it failed:**
     - ELISA (binary) â‰  PR_CHO (continuous)
     - Different assays, different antigens
     - Label distribution mismatch
   - **Lesson:** External data must match assay type AND label semantics

2. **Combined Training** (0.500 â†’ 0.461, **-7.88%**)
   - **Why worse than transfer:**
     - Data imbalance: 914 Boughter + 197 GDPa1 = 85% Boughter
     - Ridge loss dominated by wrong patterns
     - No chance to adapt to PR_CHO
   - **Lesson:** Don't merge incompatible datasets

---

## ðŸ”¬ Root Cause Analysis: Why We're Stuck at 0.500

### Problem 1: Fold 3 Catastrophe (0.216 Spearman)

Other folds: 0.48-0.67 | Fold 3: 0.216

**If we could improve Fold 3 from 0.216 â†’ 0.27:**
```python
mean([0.478, 0.556, 0.672, 0.270, 0.580]) = 0.511  # BEATS LEADER!
```

**Possible causes:**
- Fold 3 has different antibody types (nanobodies? unusual CDRs?)
- Ridge is too linear to capture Fold 3 patterns
- Embeddings don't capture Fold 3 features

**Next step:** Investigate Fold 3 antibodies specifically

### Problem 2: Ridge is Too Simple

**What Ridge does:**
```python
prediction = w1*embedding[0] + w2*embedding[1] + ... + w1280*embedding[1279]
```

**What it CAN'T do:**
- Capture nonlinear interactions (e.g., "VH hydrophobicity Ã— VL charge")
- Handle feature importance (treats all embedding dims equally)
- Adapt to heterogeneous folds (same weights for all folds)

**Solution:** Try better heads (see below)

---

## ðŸš€ Phase 2: Better Regression Heads (Nov 2025 Edition)

### Why Better Heads Matter

Current setup:
```
Frozen PLM (ESM-1v/p-IgGen) â†’ Dense embeddings (2304D) â†’ Ridge â†’ Prediction
```

**Ridge bottleneck:**
- Linear model on high-dim dense features
- No feature selection, no nonlinearity
- State-of-art for tabular regression in 2025 is NO LONGER Ridge

### The 2025 Hierarchy (Best â†’ Simplest)

#### 1. **TabPFN v2.5** (Foundation Model for Tabular) ðŸ”¥ BLEEDING EDGE

**What:** Transformer pre-trained on 10â¸ synthetic tabular datasets, SOTA on small-N regression

**Why for us:**
- Built for N=1k regime (our sweet spot!)
- Beats tuned GBDTs on small tabular benchmarks
- Zero/minimal tuning required
- "ESM + TabPFN v2.5" is a legit 2025 combo (Nature-paper flex)

**Implementation:**
```python
from tabpfn import TabPFNRegressor

# Reduce embeddings to TabPFN's sweet spot
pca = PCA(n_components=256)
X_reduced = pca.fit_transform(embeddings)

model = TabPFNRegressor()
model.fit(X_reduced, y)
```

**Expected gain:** +2-5% (handles nonlinearity + small-N regime)

**References:**
- Paper: https://arxiv.org/abs/2207.01848
- v2.5 release: Nov 2025
- GitHub: https://github.com/automl/TabPFN

---

#### 2. **LightGBM** (Gradient Boosting) ðŸ¥‡ MOST LIKELY WIN

**What:** Gradient-boosted decision trees, current king of tabular ML

**Why for us:**
- Captures nonlinear feature interactions
- Handles weird marginal distributions
- Proven winner on small-medium tabular benchmarks
- Will likely fix Fold 3 (can learn fold-specific patterns)

**Implementation:**
```python
from lightgbm import LGBMRegressor

model = LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    num_leaves=31,
    max_depth=5,
    subsample=0.8,
    colsample_bytree=0.6,
    reg_alpha=1.0,
    reg_lambda=1.0,
    random_state=42
)

model.fit(X_train, y_train,
          eval_set=[(X_val, y_val)],
          early_stopping_rounds=50,
          verbose=False)
```

**Expected gain:** +3-7% (my money pick)

**Tuning strategy:**
- Start conservative: `num_leaves=16, max_depth=4`
- Use early stopping on GDPa1 folds
- Grid search: {num_leaves: [16, 31, 64], max_depth: [4, 5, 7]}

---

#### 3. **ElasticNet** (Ridge++) ðŸƒ FASTEST TO TRY

**What:** Ridge with L1 + L2 regularization (automatic feature selection)

**Why for us:**
- Almost free to implement (swap Ridge â†’ ElasticNet)
- Knocks out noisy embedding dimensions
- Keeps linear model robustness
- If this doesn't beat Ridge, we know linear is at ceiling

**Implementation:**
```python
from sklearn.linear_model import ElasticNetCV

model = ElasticNetCV(
    l1_ratio=[0.1, 0.3, 0.5, 0.7, 0.9],
    alphas=None,  # auto CV
    cv=5,
    max_iter=10000,
    n_jobs=-1,
    random_state=42
)

model.fit(X_train, y_train)
```

**Expected gain:** +0-2% (diagnostic test)

**If ElasticNet doesn't beat Ridge by +0.01:**
â†’ Linear models are maxed out, move to LightGBM/TabPFN

---

### Recommended Execution Order

```
Step 1: ElasticNet (30 min)
  â†“
If +0.01 â†’ Submit | If not â†’ Continue
  â†“
Step 2: LightGBM (2 hours)
  â†“
If +0.02 â†’ Submit | If not â†’ Continue
  â†“
Step 3: TabPFN v2.5 (4 hours - install + tune)
  â†“
Submit best
```

**Parallel option:** Run all 3 in separate tmux sessions, compare results

---

## ðŸ“¦ New Datasets Discovered

### 1. Tessier Lab Cell Reports 2024 âœ… DOWNLOADED

**Paper:** "Human antibody polyreactivity is governed primarily by the heavy-chain complementarity-determining regions" (Oct 2024)

**Location:** `external_datasets/tessier_2024_polyreactivity/`

**Data:**
- **246,295 antibodies** with polyreactivity labels
  - Positive (polyreactive): 115,039
  - Negative (specific): 131,256
- CHO cell-based assays (SCP60, SMP60)
- Features: Biochemical descriptors (charge, hydrophobicity, etc.)
- Sequences: In supplemental datasets (Excel files)

**Why better than Boughter:**
- âœ… CHO cell assay (same as GDPa1's PR_CHO!)
- âœ… Massive dataset (246k vs 914)
- â“ Labels might still be binary (need to check)

**Status:** Downloaded, needs preprocessing

**Next steps:**
1. Extract VH/VL sequences from Excel files
2. Check if labels are continuous or binary
3. If continuous CHO scores exist â†’ THIS IS THE GOLD DATASET
4. If binary â†’ Same problem as Boughter (but bigger)

### 2. Zenodo Big Dataset (5.8 GB) ðŸ” NOT DOWNLOADED

**URL:** https://zenodo.org/doi/10.5281/zenodo.13387056

**Contents:** Unknown (need to download to inspect)

**Next step:** Download and inspect if Tessier dataset doesn't work

---

## ðŸ§¹ Repo Cleanup Plan

### Current Mess

```
â”œâ”€â”€ ginkgo_submissions/              # Baseline (0.472)
â”œâ”€â”€ ginkgo_submissions_ensemble/     # ESM-1v + ESM-2 (0.486)
â”œâ”€â”€ ginkgo_submissions_esm1v/        # ESM-1v only
â”œâ”€â”€ ginkgo_submissions_final/        # ???
â”œâ”€â”€ ginkgo_submissions_optimal/      # CURRENT BEST (0.500)
â”œâ”€â”€ experiment_results.csv           # Root file (wrong location)
â”œâ”€â”€ experiment_results/              # Boughter transfer logs
â””â”€â”€ combined_datasets/               # Boughter + GDPa1 merge
```

### Target Clean Structure

```
experiments/ginkgo_2025/
â”œâ”€â”€ submissions/
â”‚   â”œâ”€â”€ 01_baseline_esm1v/           # 0.472
â”‚   â”œâ”€â”€ 02_ensemble_esm2/            # 0.486
â”‚   â”œâ”€â”€ 03_optimal_piggen/           # 0.500 (CURRENT BEST)
â”‚   â””â”€â”€ 04_boughter_transfer/        # 0.491 (FAILED)
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ rapid_experiments.csv
â”‚   â”œâ”€â”€ top3_experiments.csv
â”‚   â””â”€â”€ boughter_transfer.csv
â””â”€â”€ logs/
    â”œâ”€â”€ rapid_experiments.txt
    â”œâ”€â”€ top3_experiments.txt
    â””â”€â”€ boughter_transfer.txt

external_datasets/
â””â”€â”€ tessier_2024_polyreactivity/     # 246k antibodies (CHO assay)

combined_datasets/                    # Boughter + GDPa1 (archived)
â”œâ”€â”€ README.md                         # Document why transfer failed
â”œâ”€â”€ boughter_training.csv
â”œâ”€â”€ ginkgo_labeled.csv
â””â”€â”€ boughter_ginkgo_combined.csv

train_datasets/ginkgo/                # GDPa1 competition data
â”œâ”€â”€ GDPa1_v1.2_sequences.csv
â””â”€â”€ GDPa1_v1.2_20250814.csv

test_datasets/ginkgo/                 # Private test set
â””â”€â”€ heldout-set-sequences.csv
```

### Git Strategy

**âœ… COMMIT:**
- All scripts (`.py`, `.sh`)
- Combined datasets (Boughter is ours)
- Results CSVs (small, useful)
- Documentation (`.md` files)
- External datasets (Tessier is public, MIT license)

**âŒ .gitignore (DO NOT COMMIT):**
- GDPa1 raw data (`train_datasets/ginkgo/*.csv`)
- GDPa1 test set (`test_datasets/ginkgo/*.csv`)
- Submission CSVs (regenerate on demand)
- Embedding caches (too large, regenerate)
- tmux logs (`.txt` in experiments/)

**Reasoning:**
- GDPa1 is competition data (respect their terms)
- Embeddings are 100+ MB (use cache locally)
- Submissions are derivatives (code is source of truth)

---

## ðŸŽ¯ Concrete Next Actions

### Immediate (Today)

1. **Clean repo structure**
   - Move files to `experiments/ginkgo_2025/`
   - Update `.gitignore`
   - Commit clean structure

2. **Implement ElasticNet head**
   - Copy `generate_optimal_submission.py` â†’ `generate_elasticnet_submission.py`
   - Swap Ridge â†’ ElasticNetCV
   - Run in tmux, compare to 0.500

3. **If ElasticNet fails, implement LightGBM**
   - Create `generate_lightgbm_submission.py`
   - Start conservative: `num_leaves=16, max_depth=4`
   - Run with early stopping

### Short-term (This Week)

4. **Preprocess Tessier dataset**
   - Extract sequences from Excel files
   - Check label distribution (binary vs continuous)
   - If continuous CHO scores â†’ retry transfer learning
   - If binary â†’ archive and move on

5. **Investigate Fold 3**
   - Extract Fold 3 antibodies
   - Analyze: CDR lengths, charge, hydrophobicity
   - Check if Fold 3 has different characteristics
   - Try fold-specific model if patterns found

6. **Implement TabPFN v2.5**
   - Install: `pip install tabpfn`
   - PCA embeddings to 256D
   - Run TabPFNRegressor with defaults
   - Compare to LightGBM

### Medium-term (Next Week)

7. **Ensemble all heads**
   - ElasticNet + LightGBM + TabPFN
   - Optimize weights with scipy
   - Final push to beat 0.504

8. **Prepare final submission**
   - Document best model in detail
   - Generate clean submission CSVs
   - Write reproducibility instructions
   - Submit to leaderboard

---

## ðŸ“š Key Lessons Learned

### 1. Transfer Learning Needs Label Alignment

**Failed:** Boughter (binary ELISA) â†’ GDPa1 (continuous PR_CHO)

**Why:** Different assays measure different things
- ELISA: Binding to specific antigens (DNA, insulin, LPS, ...)
- PR_CHO: Polyreactivity against CHO cell lysate (different antigens!)

**Lesson:** External data must match:
1. âœ… Assay type (both polyreactivity)
2. âœ… Assay readout (both CHO cells)  â† Tessier dataset!
3. âœ… Label distribution (both continuous)
4. âœ… Antibody format (both VH+VL IgGs, not nanobodies)

### 2. Data Imbalance Kills Combined Training

**Formula:**
```
If external_data >> target_data:
  â†’ Loss function dominated by external patterns
  â†’ Model never learns target task
```

**Solution:** Use transfer learning (pre-train â†’ fine-tune) instead of combined training

### 3. Linear Models Have Ceilings

Ridge @ 0.500 is probably near the ceiling for linear models on these embeddings.

**Next frontier:** Nonlinear heads (LightGBM, TabPFN)

### 4. Fold 3 is the Key

Fold 3 (0.216) is 40% worse than other folds (0.48-0.67).

**If we fix Fold 3 â†’ we beat the leader**

**Hypothesis:** Fold 3 has different antibody characteristics that Ridge can't capture

**Solution:** Investigate Fold 3 + use adaptive models (GBDT)

---

## ðŸ”— References

### Papers

1. **Sakhnini et al. (2025)** - Prediction of Antibody Non-Specificity using PLMs [bioRxiv]
2. **Boughter et al. (2020)** - Biochemical Patterns of Antibody Polyreactivity [eLife]
3. **Tessier Lab (2024)** - Human Antibody Polyreactivity Governed by Heavy Chain [Cell Reports]
4. **TabPFN (2022)** - Tabular Foundation Model [NeurIPS]

### Datasets

- **Boughter:** 914 antibodies, ELISA polyreactivity (binary)
- **GDPa1:** 246 antibodies, PR_CHO polyreactivity (continuous), 5 folds
- **Tessier:** 246k antibodies, CHO polyreactivity (binary?), public
- **Jain:** 86 antibodies, Novo parity benchmark
- **Harvey:** 141k nanobodies, PSR assay
- **Shehata:** 398 antibodies, PSR assay

### Tools

- **ESM-1v:** facebook/esm1v_t33_650M_UR90S_1
- **p-IgGen:** Exscientia/IgBert
- **ESM-2:** facebook/esm2_t33_650M_UR50D
- **LightGBM:** https://lightgbm.readthedocs.io/
- **TabPFN:** https://github.com/automl/TabPFN

---

## ðŸš¦ Status Dashboard

| Metric | Value | Target | Status |
|--------|-------|--------|--------|
| Current Score | 0.500 | 0.504 | ðŸŸ¡ -0.8% |
| Fold 0 | 0.478 | 0.50 | ðŸŸ¡ |
| Fold 1 | 0.556 | 0.50 | âœ… |
| Fold 2 | 0.672 | 0.50 | âœ… |
| **Fold 3** | **0.216** | **0.50** | **ðŸ”´ CRITICAL** |
| Fold 4 | 0.580 | 0.50 | âœ… |
| External Data | Tessier (246k) | CHO assay | âœ… Downloaded |
| Better Head | Ridge | GBDT/TabPFN | ðŸŸ¡ Pending |
| Repo Cleanup | Messy | Clean | ðŸŸ¡ In Progress |

**Next milestone:** Beat 0.504 with LightGBM or TabPFN

**Deadline:** Nov 17, 2025 (4 days remaining!)

---

**Last Updated:** 2025-11-13 07:30 PST
**Author:** Ray + Claude
**Version:** 2.0
