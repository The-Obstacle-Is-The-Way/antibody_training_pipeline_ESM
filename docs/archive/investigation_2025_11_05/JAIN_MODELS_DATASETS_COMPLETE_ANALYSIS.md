# Jain Dataset & Model Weights Complete Analysis

**Date:** 2025-11-05
**Status:** üö® **CRITICAL FINDING - Model/Dataset Interaction**

---

## Executive Summary

We tested **2 models** √ó **2 datasets** = **4 combinations** to understand the confusion matrix discrepancy.

**CRITICAL FINDING:** The confusion matrix depends on BOTH the model weights AND the dataset used!

---

## Test Matrix: 2√ó2 Comparison

| Model | Dataset | Confusion Matrix | Accuracy | Novo Match? |
|-------|---------|------------------|----------|-------------|
| **OLD (914)** | OLD (reverse-eng) | [[40, 19], [10, 17]] | 66.28% | ‚úÖ **EXACT** |
| **OLD (914)** | P5e-S2 (canonical) | [[39, 20], [10, 17]] | 65.12% | ‚ùå Off by 1 |
| **NEW (852)** | OLD (reverse-eng) | [[41, 18], [10, 17]] | 67.44% | ‚ùå Off by 1 |
| **NEW (852)** | P5e-S2 (canonical) | [[40, 19], [12, 15]] | 66.28% | ‚ùå Off by 2 |

---

## Models Used

### Model 1: OLD (boughter_vh_esm1v_logreg.pkl)
- **Created:** Nov 2, 2025 12:45:55
- **Training data:** 914 sequences (Boughter QC)
- **QC method:** X in CDRs only, empty CDRs
- **CV accuracy:** 67.5% ¬± 8.9%

### Model 2: NEW (boughter_vh_strict_qc_esm1v_logreg.pkl)
- **Created:** Nov 4, 2025 23:58:30
- **Training data:** 852 sequences (Strict QC)
- **QC method:** X anywhere, non-standard AA
- **CV accuracy:** 66.55% ¬± 7.07%

---

## Datasets Used

### Dataset 1: OLD (VH_only_jain_test_PARITY_86.csv)
- **Method:** 137 ‚Üí 94 ‚Üí 91 ‚Üí 86 (reverse-engineered)
- **QC:** Remove ELISA 1-3 ‚Üí remove 3 length outliers ‚Üí remove 5 borderline
- **Antibodies:** 59 specific / 27 non-specific

### Dataset 2: P5e-S2 (VH_only_jain_86_p5e_s2.csv)
- **Method:** 137 ‚Üí 116 ‚Üí 86 (canonical from experiments)
- **QC:** Remove ELISA 1-3 ‚Üí reclassify 5 ‚Üí remove 30 by PSR+AC-SINS
- **Antibodies:** 59 specific / 27 non-specific

**Overlap:** Only 62/86 antibodies shared (72.1%)
**Difference:** 24 antibodies different (27.9%)

---

## Detailed Results

### Test 1: OLD Model + OLD Dataset ‚úÖ NOVO PARITY

```
Model: boughter_vh_esm1v_logreg.pkl (Nov 2, 914 training)
Dataset: VH_only_jain_test_PARITY_86.csv

Confusion Matrix: [[40, 19], [10, 17]]
  TN=40, FP=19, FN=10, TP=17

Accuracy: 66.28% (57/86)
Precision: 0.4722
Recall: 0.6296
F1: 0.5397
ROC-AUC: 0.6340

‚úÖ EXACT MATCH to Novo published results!
```

---

### Test 2: OLD Model + P5e-S2 Dataset ‚ùå Off by 1

```
Model: boughter_vh_esm1v_logreg.pkl (Nov 2, 914 training)
Dataset: VH_only_jain_86_p5e_s2.csv

Confusion Matrix: [[39, 20], [10, 17]]
  TN=39, FP=20, FN=10, TP=17

Accuracy: 65.12% (56/86)
Precision: 0.4595
Recall: 0.6296
F1: 0.5312
ROC-AUC: 0.6560

‚ùå Off by 1: TN=39 vs 40, FP=20 vs 19
```

**Difference:** One specific antibody predicted as non-specific
**Impact:** 1.16% accuracy drop

---

### Test 3: NEW Model + OLD Dataset ‚ùå Off by 1

```
Model: boughter_vh_strict_qc_esm1v_logreg.pkl (Nov 4, 852 training)
Dataset: VH_only_jain_test_PARITY_86.csv

Confusion Matrix: [[41, 18], [10, 17]]
  TN=41, FP=18, FN=10, TP=17

Accuracy: 67.44% (58/86)
Precision: 0.4848
Recall: 0.5926
F1: 0.5333
ROC-AUC: 0.6503

‚ùå Off by 1: TN=41 vs 40, FP=18 vs 19
‚úÖ BETTER than Novo (+1.16% accuracy)
```

**Difference:** One non-specific antibody predicted as specific
**Impact:** Better performance than published!

---

### Test 4: NEW Model + P5e-S2 Dataset ‚ùå Off by 2

```
Model: boughter_vh_strict_qc_esm1v_logreg.pkl (Nov 4, 852 training)
Dataset: VH_only_jain_86_p5e_s2.csv

Confusion Matrix: [[40, 19], [12, 15]]
  TN=40, FP=19, FN=12, TP=15

Accuracy: 63.95% (55/86)
Precision: 0.4688
Recall: 0.5556
F1: 0.5085
ROC-AUC: 0.6478

‚ùå Off by 2: FN=12 vs 10, TP=15 vs 17
```

**Difference:** Two true positives misclassified as false negatives
**Impact:** 2.33% accuracy drop

---

## Key Findings

### üîç Finding 1: Model-Dataset Interaction

**The confusion matrix is NOT just about the dataset OR the model - it's about the COMBINATION!**

```
OLD model + OLD dataset = [[40, 19], [10, 17]] ‚úÖ EXACT NOVO MATCH
OLD model + P5e-S2      = [[39, 20], [10, 17]] ‚ùå Off by 1
NEW model + OLD dataset = [[41, 18], [10, 17]] ‚ùå Off by 1 (better!)
NEW model + P5e-S2      = [[40, 19], [12, 15]] ‚ùå Off by 2
```

### üîç Finding 2: Novo Used OLD Model + OLD Dataset

**Evidence:**
- Only OLD model (914 training) + OLD dataset achieves exact [[40, 19], [10, 17]]
- OLD model was trained Nov 2 (before P5e-S2 experiments started Nov 3)
- P5e-S2 experiments were likely tested with a DIFFERENT model or configuration

### üîç Finding 3: P5e-S2 Documentation May Be Wrong

**Discrepancy:**
- `experiments/novo_parity/EXACT_MATCH_FOUND.md` claims P5e-S2 gives [[40, 19], [10, 17]]
- Our testing shows P5e-S2 gives [[39, 20], [10, 17]] with OLD model
- **Hypothesis:** The experiments used a different model or hyperparameters

### üîç Finding 4: NEW Model Improves OLD Dataset

**Surprising result:**
- NEW model (852 strict QC) + OLD dataset = 67.44% accuracy
- This is BETTER than Novo's 66.28%!
- Confusion matrix: [[41, 18], [10, 17]]

**Interpretation:** Stricter training QC (852) creates a more conservative classifier that reduces false positives on the OLD test set.

---

## Antibody-Level Analysis: What Changed?

### Test 1 vs Test 2 (OLD Model, Different Datasets)

**28% different antibodies (24 out of 86):**

**Only in OLD dataset (24):**
- atezolizumab, brodalumab, daclizumab, epratuzumab, etrolizumab
- evolocumab, figitumumab, foralumab, glembatumumab, guselkumab
- lumiliximab, nivolumab, obinutuzumab, ozanezumab, pinatuzumab
- radretumab, ranibizumab, reslizumab, rilotumumab, seribantumab
- tigatuzumab, visilizumab, zalutumumab, zanolimumab

**Only in P5e-S2 dataset (24):**
- bapineuzumab, bavituximab, belimumab, bevacizumab, carlumab
- cetuximab, codrituzumab, denosumab, dupilumab, fletikumab
- galiximab, ganitumab, gantenerumab, gemtuzumab, girentuximab
- imgatuzumab, lampalizumab, lebrikizumab, nimotuzumab, otelixizumab
- patritumab, ponezumab, secukinumab, tabalumab

**Key observations:**
- All 62 shared antibodies have SAME labels in both datasets
- All 62 shared antibodies have SAME predictions with OLD model
- The 1-antibody confusion matrix difference comes from the DIFFERENT 24 antibodies

---

## Implications

### For Documentation

**CRITICAL:** The statement "P5e-S2 achieves exact Novo parity" is **MISLEADING**.

- **Reality:** OLD dataset + OLD model achieves exact parity
- **P5e-S2:** Off by 1 with OLD model, off by 2 with NEW model

**Need to clarify:**
1. Which model was used in `experiments/novo_parity/` testing?
2. Was it the Nov 2 OLD model or a different one?
3. If different, where are those model weights?

### For Future Work

**Recommendation:** Use **OLD model + OLD dataset** for Novo benchmarking

**Why?**
- ‚úÖ Achieves exact confusion matrix [[40, 19], [10, 17]]
- ‚úÖ Matches published 66.28% accuracy
- ‚úÖ Validates our replication methodology

**Alternative:** Use **NEW model + OLD dataset** if you want better performance (67.44%)

---

## Questions to Resolve

### Q1: What model did experiments/novo_parity use?

**Investigation needed:**
- Check git history for models/ folder on Nov 3-4
- Look for cached model files in experiments/novo_parity/
- Check if different hyperparameters were used

### Q2: Why does P5e-S2 not match if it's "canonical"?

**Hypothesis A:** P5e-S2 methodology is correct, but tested with different model
**Hypothesis B:** OLD dataset accidentally got the right answer
**Hypothesis C:** Both datasets are valid, just different QC philosophies

### Q3: Should we use OLD or P5e-S2 going forward?

**For Novo benchmarking:** Use OLD (exact parity achieved)
**For general use:** Use P5e-S2 (more principled methodology)
**For best performance:** Use NEW model + OLD dataset (67.44%)

---

## Recommended Actions

### Immediate (Critical)

1. **Investigate experiments model:**
   - Find which model weights were used for P5e-S2 testing
   - Check if experiments/ has cached models
   - Review git history for models/ folder

2. **Test P5e-S2 with correct model:**
   - If experiments used different weights, test those
   - Document which combination gives [[40, 19], [10, 17]]

3. **Update documentation:**
   - Clarify that parity requires BOTH specific model AND dataset
   - Document all 4 test combinations
   - Add warnings about model-dataset interaction

### Short-term (Cleanup)

1. **Archive appropriately:**
   - Keep OLD dataset as "novo_parity_benchmark"
   - Keep P5e-S2 as "jain_canonical_methodology"
   - Document which to use for what purpose

2. **Update scripts:**
   - Add MODEL + DATASET compatibility checks
   - Warn users if they mix incompatible combinations

3. **Create verification test:**
   - Script that checks confusion matrix for all 4 combinations
   - Alerts if OLD+OLD doesn't give [[40, 19], [10, 17]]

---

## File Inventory

### Models
```
models/
‚îú‚îÄ‚îÄ boughter_vh_esm1v_logreg.pkl              # OLD (Nov 2, 914 training) ‚úÖ Use for benchmarking
‚îî‚îÄ‚îÄ boughter_vh_strict_qc_esm1v_logreg.pkl    # NEW (Nov 4, 852 strict QC) ‚ö° Better performance
```

### Datasets
```
test_datasets/jain/
‚îú‚îÄ‚îÄ VH_only_jain_test_PARITY_86.csv           # OLD reverse-engineered ‚úÖ Use for benchmarking
‚îú‚îÄ‚îÄ VH_only_jain_86_p5e_s2.csv                # P5e-S2 canonical fragment (created today)
‚îî‚îÄ‚îÄ jain_86_novo_parity.csv                   # P5e-S2 full (rich columns)
```

### Test Results
```
test_results/
‚îú‚îÄ‚îÄ jain_old_verification/                    # Test 1: OLD model + OLD dataset ‚úÖ
‚îú‚îÄ‚îÄ jain_p5e_s2_verification/                 # Test 2: OLD model + P5e-S2 ‚ùå
‚îú‚îÄ‚îÄ matrix_test_new_old/                      # Test 3: NEW model + OLD dataset ‚ö°
‚îî‚îÄ‚îÄ matrix_test_new_p5e/                      # Test 4: NEW model + P5e-S2 ‚ùå
```

---

## Summary

**The confusion matrix [[40, 19], [10, 17]] is achieved by:**
- ‚úÖ OLD model (914 training) + OLD dataset (reverse-engineered)
- ‚ùå OLD model + P5e-S2 dataset (off by 1)
- ‚ùå NEW model + OLD dataset (off by 1, but better accuracy)
- ‚ùå NEW model + P5e-S2 dataset (off by 2)

**Conclusion:** Novo used the OLD dataset methodology, not P5e-S2.

**Next step:** Investigate which model was used in experiments/novo_parity/ testing.

---

**Generated:** 2025-11-05 08:40:00
**Status:** üö® CRITICAL - REQUIRES INVESTIGATION
